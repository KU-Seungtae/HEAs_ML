{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4433b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] 10% done (600/6000)\n",
      "[RF] 20% done (1200/6000)\n",
      "[RF] 30% done (1800/6000)\n",
      "[RF] 40% done (2400/6000)\n",
      "[RF] 50% done (3000/6000)\n",
      "[RF] 60% done (3600/6000)\n",
      "[RF] 70% done (4200/6000)\n",
      "[RF] 80% done (4800/6000)\n",
      "[RF] 90% done (5400/6000)\n",
      "[RF] 100% done (6000/6000)\n",
      "RF: Test_R2=0.7865, Test_RMSE=233.2481 | saved: best_model_RF.pkl\n",
      "[GBR] 10% done (820/8192)\n",
      "[GBR] 20% done (1639/8192)\n",
      "[GBR] 30% done (2458/8192)\n",
      "[GBR] 40% done (3277/8192)\n",
      "[GBR] 50% done (4096/8192)\n",
      "[GBR] 60% done (4916/8192)\n",
      "[GBR] 70% done (5735/8192)\n",
      "[GBR] 80% done (6554/8192)\n",
      "[GBR] 90% done (7373/8192)\n",
      "[GBR] 100% done (8192/8192)\n",
      "GBR: Test_R2=0.8538, Test_RMSE=192.9876 | saved: best_model_GBR.pkl\n",
      "[XGB] 10% done (51200/512000)\n",
      "[XGB] 20% done (102400/512000)\n",
      "[XGB] 30% done (153600/512000)\n",
      "[XGB] 40% done (204800/512000)\n",
      "[XGB] 50% done (256000/512000)\n",
      "[XGB] 60% done (307200/512000)\n",
      "[XGB] 70% done (358400/512000)\n",
      "[XGB] 80% done (409600/512000)\n",
      "[XGB] 90% done (460800/512000)\n",
      "[XGB] 100% done (512000/512000)\n",
      "XGB: Test_R2=0.8173, Test_RMSE=215.7462 | saved: best_model_XGB.pkl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "TEST_SIZE = 0.2\n",
    "CV = 3\n",
    "\n",
    "\n",
    "def _sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = df.columns.astype(str)\n",
    "    cols = [re.sub(r\"[\\[\\]<>]\", \"\", c) for c in cols]\n",
    "    cols = [re.sub(r\"\\s+\", \"_\", c).strip(\"_\") for c in cols]\n",
    "    df = df.copy()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_xy(file_path: str, x_cols=(0, 20), y_col=20):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = _sanitize_columns(df)\n",
    "    X = df.iloc[:, x_cols[0] : x_cols[1]]\n",
    "    y = df.iloc[:, y_col]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def _progress_marks(total: int, step_pct: int = 10):\n",
    "    marks = set()\n",
    "    for p in range(step_pct, 101, step_pct):\n",
    "        k = int(np.ceil(total * p / 100))\n",
    "        marks.add(max(1, k))\n",
    "    return marks\n",
    "\n",
    "\n",
    "def run_gridsearch(model, X_train, y_train, param_grid: dict, tag: str):\n",
    "    grid = list(ParameterGrid(param_grid))\n",
    "    total = len(grid)\n",
    "    marks = _progress_marks(total, step_pct=10)\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for i, params in enumerate(grid, start=1):\n",
    "        est = model.__class__(**{**model.get_params(), **params})\n",
    "        score = cross_val_score(\n",
    "            est, X_train, y_train,\n",
    "            cv=CV, scoring=\"r2\", n_jobs=1\n",
    "        ).mean()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = float(score)\n",
    "            best_params = params\n",
    "\n",
    "        if i in marks:\n",
    "            pct = int(round(i / total * 100))\n",
    "            print(f\"[{tag}] {pct}% done ({i}/{total})\")\n",
    "\n",
    "    best_est = model.__class__(**{**model.get_params(), **best_params})\n",
    "    best_est.fit(X_train, y_train)\n",
    "    return best_est, best_params, float(best_score)\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, pred) ** 0.5\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    return float(rmse), float(r2)\n",
    "\n",
    "\n",
    "def fit_single_stage(model, X_train, y_train, X_test, y_test, grid, tag: str):\n",
    "    best_est, best_params, best_cv_r2 = run_gridsearch(model, X_train, y_train, grid, tag)\n",
    "    rmse, r2 = evaluate(best_est, X_test, y_test)\n",
    "\n",
    "    model_path = f\"best_model_{tag}.pkl\"\n",
    "    joblib.dump(best_est, model_path)\n",
    "\n",
    "    row = {\n",
    "        \"Model\": tag,\n",
    "        \"Best_CV_R2\": best_cv_r2,\n",
    "        \"Best_Params\": str(best_params),\n",
    "        \"Test_RMSE\": rmse,\n",
    "        \"Test_R2\": r2,\n",
    "        \"Model_Path\": model_path,\n",
    "    }\n",
    "    print(f\"{tag}: Test_R2={r2:.4f}, Test_RMSE={rmse:.4f} | saved: {model_path}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def main():\n",
    "    file_path = \"/home/Seungtae/Research/251216_HEAs_revision/HEAs-ML_training.xlsx\"\n",
    "\n",
    "    X, y = load_xy(file_path, x_cols=(0, 20), y_col=20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    rf_grid = {\n",
    "        \"n_estimators\": [100, 200, 300, 500, 700],\n",
    "        \"max_depth\": [10, 20, 30, 50, 70, None],\n",
    "        \"min_samples_split\": [2, 5, 10, 15],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 8],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", 0.2, 0.5, 0.8],\n",
    "        \"bootstrap\": [True, False],\n",
    "    }\n",
    "\n",
    "    gbr_grid = {\n",
    "        \"n_estimators\": [100, 200, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 5, 6],\n",
    "        \"min_samples_split\": [2, 5, 10, 15],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "        \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    }\n",
    "\n",
    "    xgb_grid = {\n",
    "        \"n_estimators\": [100, 200, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 5, 6, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"gamma\": [0, 0.1, 0.2, 0.3],\n",
    "        \"reg_alpha\": [0, 0.01, 0.1, 1],\n",
    "        \"reg_lambda\": [1, 1.5, 2, 3],\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    rows.append(\n",
    "        fit_single_stage(\n",
    "            RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=1),\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            rf_grid, \"RF\"\n",
    "        )\n",
    "    )\n",
    "    rows.append(\n",
    "        fit_single_stage(\n",
    "            GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            gbr_grid, \"GBR\"\n",
    "        )\n",
    "    )\n",
    "    rows.append(\n",
    "        fit_single_stage(\n",
    "            XGBRegressor(objective=\"reg:squarederror\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            xgb_grid, \"XGB\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(rows).to_excel(\"gridsearch_summary_single_stage.xlsx\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb91c086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Test_R2=0.7865, Test_RMSE=233.2481, Test_MAPE=28.88%\n",
      "GBR: Test_R2=0.8538, Test_RMSE=192.9876, Test_MAPE=23.62%\n",
      "XGB: Test_R2=0.8173, Test_RMSE=215.7462, Test_MAPE=27.06%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "\n",
    "def _sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = df.columns.astype(str)\n",
    "    cols = [re.sub(r\"[\\[\\]<>]\", \"\", c) for c in cols]\n",
    "    cols = [re.sub(r\"\\s+\", \"_\", c).strip(\"_\") for c in cols]\n",
    "    out = df.copy()\n",
    "    out.columns = cols\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_xy(file_path: str, x_cols=(0, 20), y_col=20):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = _sanitize_columns(df)\n",
    "    X = df.iloc[:, x_cols[0] : x_cols[1]]\n",
    "    y = df.iloc[:, y_col]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_metrics(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    r2 = float(r2_score(y_test, pred))\n",
    "    mape = float(mean_absolute_percentage_error(y_test, pred) * 100.0)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_path = \"/home/Seungtae/Research/251216_HEAs_revision/HEAs-ML_training.xlsx\"\n",
    "    X, y = load_xy(data_path, x_cols=(0, 20), y_col=20)\n",
    "\n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    model_paths = {\n",
    "        \"RF\": \"best_model_RF.pkl\",\n",
    "        \"GBR\": \"best_model_GBR.pkl\",\n",
    "        \"XGB\": \"best_model_XGB.pkl\",\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for name, path in model_paths.items():\n",
    "        model = joblib.load(path)\n",
    "        r2, rmse, mape = evaluate_metrics(model, X_test, y_test)\n",
    "\n",
    "        rows.append({\n",
    "            \"Model\": name,\n",
    "            \"Test_R2\": r2,\n",
    "            \"Test_RMSE\": rmse,\n",
    "            \"Test_MAPE(%)\": mape,\n",
    "            \"Model_Path\": path,\n",
    "        })\n",
    "\n",
    "        print(f\"{name}: Test_R2={r2:.4f}, Test_RMSE={rmse:.4f}, Test_MAPE={mape:.2f}%\")\n",
    "\n",
    "    pd.DataFrame(rows).to_excel(\"test_metrics_from_saved_models.xlsx\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d35f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "251216_HEAs_revision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
