{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56631421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    ExtraTreesRegressor, AdaBoostRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "# Basic setup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "# Load dataset\n",
    "file_path = os.path.join(os.getcwd(), \"HEAs-ML_training.xlsx\")\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Features and target (last column = YS)\n",
    "X_df = data.iloc[:, :-1].copy()\n",
    "y_ser = data.iloc[:, -1].copy()\n",
    "\n",
    "# Ensure numeric and convert to numpy arrays\n",
    "X = X_df.apply(pd.to_numeric, errors=\"raise\").to_numpy()\n",
    "y = pd.to_numeric(y_ser, errors=\"raise\").to_numpy()\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Model definitions and search spaces (only this part tuned)\n",
    "model_dict = {\n",
    "    \"XGB\": (XGBRegressor, {\n",
    "        \"n_estimators\": (100, 600),\n",
    "        \"max_depth\": (3, 12),\n",
    "        \"learning_rate\": (0.005, 0.3),\n",
    "        \"colsample_bytree\": (0.6, 1.0),\n",
    "        \"subsample\": (0.6, 1.0)\n",
    "    }),\n",
    "    \"RF\": (RandomForestRegressor, {\n",
    "        \"n_estimators\": (100, 600),\n",
    "        \"max_depth\": (3, 20),\n",
    "        \"min_samples_split\": (4, 40),\n",
    "        \"min_samples_leaf\": (2, 15)\n",
    "    }),\n",
    "    \"GBR\": (GradientBoostingRegressor, {\n",
    "        \"n_estimators\": (100, 600),\n",
    "        \"max_depth\": (2, 8),\n",
    "        \"learning_rate\": (0.005, 0.2),\n",
    "        \"subsample\": (0.6, 1.0)\n",
    "    }),\n",
    "    \"LGB\": (LGBMRegressor, {\n",
    "        \"n_estimators\": (100, 600),\n",
    "        \"max_depth\": (3, 15),\n",
    "        \"learning_rate\": (0.005, 0.2),\n",
    "        \"subsample\": (0.6, 1.0),\n",
    "        \"colsample_bytree\": (0.6, 1.0)\n",
    "    }),\n",
    "    \"ADA\": (AdaBoostRegressor, {\n",
    "        \"n_estimators\": (50, 400),\n",
    "        \"learning_rate\": (0.01, 0.5)\n",
    "    }),\n",
    "    \"DT\": (DecisionTreeRegressor, {\n",
    "        \"max_depth\": (2, 15),\n",
    "        \"min_samples_split\": (4, 40),\n",
    "        \"min_samples_leaf\": (3, 20)\n",
    "    }),\n",
    "    \"ET\": (ExtraTreesRegressor, {\n",
    "        \"n_estimators\": (100, 600),\n",
    "        \"max_depth\": (3, 20),\n",
    "        \"min_samples_split\": (4, 40),\n",
    "        \"min_samples_leaf\": (2, 15)\n",
    "    }),\n",
    "    \"Ridge\": (Ridge, {\"alpha\": (1e-3, 100.0)}),\n",
    "}\n",
    "\n",
    "os.makedirs(\"OptimizationLogs\", exist_ok=True)\n",
    "results = []\n",
    "\n",
    "\n",
    "def build_model(model_class, model_name, params):\n",
    "    base = model_class()\n",
    "    kwargs = params.copy()\n",
    "    if \"random_state\" in base.get_params():\n",
    "        kwargs[\"random_state\"] = RANDOM_STATE\n",
    "    if \"n_jobs\" in base.get_params():\n",
    "        kwargs[\"n_jobs\"] = -1\n",
    "    if model_name == \"XGB\":\n",
    "        kwargs[\"tree_method\"] = \"hist\"\n",
    "        kwargs[\"device\"] = \"cuda\"\n",
    "    if model_name == \"LGB\":\n",
    "        kwargs[\"verbose\"] = -1\n",
    "    return model_class(**kwargs)\n",
    "\n",
    "\n",
    "# Hyperparameter tuning with 5-fold CV\n",
    "for model_name, (model_class, param_dict) in model_dict.items():\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {}\n",
    "        for key, val in param_dict.items():\n",
    "            if isinstance(val[0], int):\n",
    "                params[key] = trial.suggest_int(key, val[0], val[1])\n",
    "            else:\n",
    "                params[key] = trial.suggest_float(key, val[0], val[1], log=True)\n",
    "\n",
    "        model = build_model(model_class, model_name, params)\n",
    "        mape_list = []\n",
    "\n",
    "        for tr_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X[tr_idx], X[val_idx]\n",
    "            y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_val)\n",
    "            mape_list.append(mean_absolute_percentage_error(y_val, pred) * 100)\n",
    "\n",
    "        return float(np.mean(mape_list))\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Save optimization log\n",
    "    df_trials = pd.DataFrame([\n",
    "        {**t.params, \"MAPE_CV\": t.value} for t in study.trials\n",
    "    ])\n",
    "    df_trials.to_excel(f\"OptimizationLogs/OptimizationLog_YS_{model_name}.xlsx\", index=False)\n",
    "\n",
    "    # Re-evaluate tuned model with 5-fold CV\n",
    "    best_params = study.best_params\n",
    "    cv_r2, cv_mape, cv_rmse = [], [], []\n",
    "\n",
    "    for tr_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[tr_idx], X[val_idx]\n",
    "        y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        tuned_model = build_model(model_class, model_name, best_params)\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        pred = tuned_model.predict(X_val)\n",
    "\n",
    "        cv_r2.append(r2_score(y_val, pred))\n",
    "        cv_mape.append(mean_absolute_percentage_error(y_val, pred) * 100)\n",
    "        cv_rmse.append(np.sqrt(mean_squared_error(y_val, pred)))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"R2_mean\": np.mean(cv_r2),\n",
    "        \"MAPE_mean\": np.mean(cv_mape),\n",
    "        \"RMSE_mean\": np.mean(cv_rmse),\n",
    "        \"R2_std\": np.std(cv_r2),\n",
    "        \"MAPE_std\": np.std(cv_mape),\n",
    "        \"RMSE_std\": np.std(cv_rmse)\n",
    "    })\n",
    "\n",
    "    final_model = build_model(model_class, model_name, best_params)\n",
    "    final_model.fit(X, y)\n",
    "    joblib.dump(final_model, f\"YS_best_model_{model_name}.pkl\")\n",
    "\n",
    "# Linear regression baseline\n",
    "lr = LinearRegression()\n",
    "cv_r2, cv_mape, cv_rmse = [], [], []\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[tr_idx], X[val_idx]\n",
    "    y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred = lr.predict(X_val)\n",
    "\n",
    "    cv_r2.append(r2_score(y_val, pred))\n",
    "    cv_mape.append(mean_absolute_percentage_error(y_val, pred) * 100)\n",
    "    cv_rmse.append(np.sqrt(mean_squared_error(y_val, pred)))\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"LR\",\n",
    "    \"R2_mean\": np.mean(cv_r2),\n",
    "    \"MAPE_mean\": np.mean(cv_mape),\n",
    "    \"RMSE_mean\": np.mean(cv_rmse),\n",
    "    \"R2_std\": np.std(cv_r2),\n",
    "    \"MAPE_std\": np.std(cv_mape),\n",
    "    \"RMSE_std\": np.std(cv_rmse) \n",
    "})\n",
    "\n",
    "lr.fit(X, y)\n",
    "joblib.dump(lr, \"YS_best_model_LR.pkl\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(\"All_Models_result_HEA_5fold.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "251216_HEAs_revision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
